{
  "cells": [
    {
      "metadata": {
        "_uuid": "908cc6a5d46bae29f822e0dd353fd34947898706",
        "_cell_guid": "b6103d10-10b9-44dd-8c7c-ce71bb390833",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "import sys, os, re, csv, codecs, numpy as np, pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\nfrom keras.layers import Bidirectional, GlobalMaxPool1D,Bidirectional\nfrom keras.models import Model\nfrom keras import initializers, regularizers, constraints, optimizers, layers\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport gensim.models.keyedvectors as word2vec\nimport gc\nimport numpy as np",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "bead9ea1dfe1846027bfcd94a264a110b6f06e81",
        "_cell_guid": "05c286a1-2510-4c38-8922-6f4d8dcad863",
        "trusted": false
      },
      "cell_type": "code",
      "source": "train = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/train.csv')\ntest = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/test.csv')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "a410746ad2dd36a2b9719382e04431eee5d34c68",
        "_cell_guid": "7e8ad169-36d2-4f13-8a6d-0b829451d6be",
        "trusted": false
      },
      "cell_type": "code",
      "source": "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\ny = train[list_classes].values\nlist_sentences_train = train[\"comment_text\"]\nlist_sentences_test = test[\"comment_text\"]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "a46ed61c7a46e6201d070531ab1794e998268c0e",
        "_cell_guid": "3d2dad9a-7ce2-42a7-be74-c737618294aa",
        "trusted": false
      },
      "cell_type": "code",
      "source": "max_features = 20000\ntokenizer = Tokenizer(num_words=max_features)\ntokenizer.fit_on_texts(list(list_sentences_train))\nlist_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\nlist_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "b9e0c623fb56fa637df7a9f0659d36f9c639ac51",
        "_cell_guid": "7d7a8d69-2ade-472b-8c6b-fdb6a916f24c",
        "trusted": false
      },
      "cell_type": "code",
      "source": "maxlen = 100\nX_t = pad_sequences(list_tokenized_train, maxlen=maxlen)\nX_te = pad_sequences(list_tokenized_test, maxlen=maxlen)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "fc2ad52bb6b418694dca15370c6b9bc47b2e304b",
        "_cell_guid": "c884b17c-3365-4f05-bad3-b90928e07719",
        "trusted": false
      },
      "cell_type": "code",
      "source": "def loadEmbeddingMatrix(typeToLoad):\n    if(typeToLoad==\"glove\"):\n        EMBEDDING_FILE='../input/glove-twitter/glove.twitter.27B.25d.txt'\n        embed_size = 25\n    elif(typeToLoad==\"word2vec\"):\n        word2vecDict = word2vec.KeyedVectors.load_word2vec_format(\"../input/googlenewsvectorsnegative300/GoogleNews-vectors-negative300.bin\", binary=True)\n        embed_size = 300\n    elif(typeToLoad==\"fasttext\"):\n        EMBEDDING_FILE='../input/fasttext/wiki.simple.vec'\n        embed_size = 300\n\n    if(typeToLoad==\"glove\" or typeToLoad==\"fasttext\" ):\n        embeddings_index = dict()\n            #Transfer the embedding weights into a dictionary by iterating through every line of the file.\n        f = open(EMBEDDING_FILE)\n        for line in f:\n            values = line.split()\n                #first index is word\n            word = values[0]\n                #store the rest of the values in the array as a new array\n            try:\n                coefs = np.asarray(values[1:], dtype='float32')\n            except ValueError:\n                pass\n            embeddings_index[word] = coefs #50 dimensions\n        f.close()\n        print('Loaded %s word vectors.' % len(embeddings_index))\n    else:\n        embeddings_index = dict()\n        for word in word2vecDict.wv.vocab:\n            embeddings_index[word] = word2vecDict.word_vec(word)\n        print('Loaded %s word vectors.' % len(embeddings_index))\n            \n    gc.collect()\n        #We get the mean and standard deviation of the embedding weights so that we could maintain the \n        #same statistics for the rest of our own random generated weights. \n    all_embs = np.stack(list(embeddings_index.values()))\n    emb_mean,emb_std = all_embs.mean(), all_embs.std()\n        \n    nb_words = len(tokenizer.word_index)\n        #We are going to set the embedding size to the pretrained dimension as we are replicating it.\n        #the size will be Number of Words in Vocab X Embedding Size\n    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n    gc.collect()\n\n        #With the newly created embedding matrix, we'll fill it up with the words that we have in both \n        #our own dictionary and loaded pretrained embedding. \n    embeddedCount = 0\n    for word, i in tokenizer.word_index.items():\n        i-=1\n            #then we see if this word is in glove's dictionary, if yes, get the corresponding weights\n        embedding_vector = embeddings_index.get(word)\n            #and store inside the embedding matrix that we will train later on.\n        if embedding_vector is not None: \n            embedding_matrix[i] = embedding_vector\n            embeddedCount+=1\n    print('total embedded:',embeddedCount,'common words')\n        \n    del(embeddings_index)\n    gc.collect()\n        \n        #finally, return the embedding matrix\n    return embedding_matrix",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b4981dc087c111871b303867491fc7480316c6f2",
        "_cell_guid": "df4161dc-6900-4be0-ab99-0dd0c79afa1c"
      },
      "cell_type": "markdown",
      "source": "The function would return a new embedding matrix that has the loaded weights from the pretrained embeddings for the common words we have, and randomly initialized numbers that has the same mean and standard deviation for the rest of the weights in this matrix."
    },
    {
      "metadata": {
        "_uuid": "5482edd9abbcaf24e136a2c3b50f5d350cc01526",
        "_cell_guid": "77c36d68-86d4-4b7f-8099-c8acad87d116"
      },
      "cell_type": "markdown",
      "source": "Let's move on and load our first embeddings from Word2Vec."
    },
    {
      "metadata": {
        "_uuid": "71c5959cf97fec554a9a44809c3947617915f4a1",
        "_cell_guid": "dea6a774-9c3d-4b20-be59-225c5cb789de",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "def get_coefs(word, *arr): \n    return word, np.asarray(arr, dtype='float32')\n\ndef embed_vec(EMBEDDING_FILE,embed_size, max_features = 20000,maxlen = 100):\n    embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(EMBEDDING_FILE))\n    all_embs = np.stack(embeddings_index.values())\n    emb_mean,emb_std = all_embs.mean(), all_embs.std()\n\n    word_index = tokenizer.word_index\n    nb_words = min(max_features, len(word_index))\n    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n    for word, i in word_index.items():\n        if i >= max_features: continue\n        embedding_vector = embeddings_index.get(word)\n        if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n    print(embedding_matrix.shape)\n    return embedding_matrix",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "8709b486e16f2f8d622afdcc3715025bd69e785e",
        "_cell_guid": "a117696b-2428-4692-baff-cc2adc2e2793",
        "trusted": false
      },
      "cell_type": "code",
      "source": "EMBEDDING_FILE_fast = '../input/fasttext-crawl-300d-2m/crawl-300d-2M.vec'\nEMBEDDING_FILE_glove = '../input/glove6b50d/glove.6B.50d.txt'\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "_uuid": "33f70961197d4e7f2e2c4ac77e5c48476b98f166",
        "_cell_guid": "a4e7b312-a91e-49e1-8131-46655ef8b9b0",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "embedding_matrix_fast = embed_vec(EMBEDDING_FILE_fast,embed_size=300)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "_uuid": "f6c844064e92b630a87d5389ab1d45ba3bd59d11",
        "_cell_guid": "1dd12127-6b2a-4271-93a8-dda4db6cd405",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "embedding_matrix_glove = embed_vec(EMBEDDING_FILE_glove,embed_size=50)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8faa83f63a008bf6b0a151f854eeac23ab19410d",
        "_cell_guid": "5b7702c7-3e85-4915-b809-8c3020ef8989",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "from keras.utils import to_categorical\nfrom keras.layers import Dense, Input, Flatten, Dropout, Merge, BatchNormalization\nfrom keras.layers import Conv1D, MaxPooling1D, Embedding\nfrom keras.layers import LSTM, Bidirectional \nfrom keras.models import Model\nfrom keras.callbacks import EarlyStopping",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e0d35cc890edb872c9b0576cb3f6ef51daa3fe36",
        "_cell_guid": "8519fc8b-c2e0-48e8-b0d4-2a427dd6c53f",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "def cnn_model(embedding_matrix):\n    embedding_layer = Embedding(max_features, \n                                embedding_matrix.shape[1],\n                                weights=[embedding_matrix],\n                                trainable=False)\n\n    sequence_input = Input(shape=(maxlen,))\n    embedded_sequences = embedding_layer(sequence_input)\n\n    convs = []\n    filter_sizes = [3,4,5]\n\n    for filter_size in filter_sizes:\n        l_conv = BatchNormalization()(Conv1D(filters=128, kernel_size=filter_size, activation='relu')(embedded_sequences))\n        l_pool = MaxPooling1D(pool_size=3)(l_conv)\n        convs.append(l_pool)\n\n    l_merge = Merge(mode='concat', concat_axis=1)(convs)\n\n    # add a 1D convnet with global maxpooling, instead of Yoon Kim model\n    conv = BatchNormalization()(Conv1D(filters=128, kernel_size=3, activation='relu')(embedded_sequences))\n    pool = MaxPooling1D(pool_size=3)(conv)\n\n    #x = Dropout(0.5)(pool)\n    x = Dropout(0.5)(l_merge) \n    x = Flatten()(x)\n    x = BatchNormalization()(Dense(128, activation='relu')(x))\n    x = Dropout(0.5)(x)\n\n    preds = Dense(len(list(list_classes)), activation='sigmoid')(x)\n\n    model = Model(sequence_input, preds)\n    model.compile(loss='binary_crossentropy',\n                  optimizer='adam',\n                  metrics=['acc'])\n    return model    ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fe20bdce08d5c1d38f3241956d4d1abc442c34ba",
        "_cell_guid": "8076ef9c-fb8c-4a6d-8e1a-3163e350ffd3",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "model = cnn_model(embedding_matrix_glove)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "2a5feae023ffbca09f42e849aa1f725440b59c7d",
        "_cell_guid": "1ce978e1-ec45-4ce4-aa25-56b8d26074eb",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#define callbacks\nearly_stopping = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=4, verbose=1)\ncallbacks_list = [early_stopping]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": false,
        "_uuid": "c7a3cff7916990deaa38228dab5e1edb441886ec",
        "scrolled": false,
        "_cell_guid": "4dbd724d-e546-417d-b37b-242ea24a362f",
        "_kg_hide-output": false,
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "num_epochs = 3\nbatch_size = 32\nhist = model.fit(X_t, y, \n                 epochs=num_epochs, \n                 callbacks=callbacks_list, \n                 validation_split=0.2, shuffle=True, batch_size=batch_size)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fe57c166d02faaa4486e3e75b572563cb6cd7db3",
        "_cell_guid": "162f04e3-1c08-499a-a7bd-faaf32e209c5",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "y_test = model.predict(X_te, batch_size=32, verbose=1)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d394d9e77f67e716e4a92b13fab6518830e4ca33",
        "_cell_guid": "f4b16653-059d-4de9-aa5a-b596e9dcbb1d",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "model.save_weights(\"cnn_model_glove.h5\")\nprint(\"Saved model to disk\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "3e6887aa9805159caf9b83b115a16ed1b03e3c2a",
        "_cell_guid": "8020b8d4-e55a-4618-86f0-cb2af0832698",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "submission_df = pd.DataFrame(columns=['id'] + list_classes)\nsubmission_df['id'] = test['id'].values \nsubmission_df[list_classes] = y_test \nsubmission_df.to_csv(\"./cnn_submission_glove.csv\", index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "53c3b6a927f74c861662d4e66e04ad95ab3e16fa",
        "_cell_guid": "0958f04a-1127-44c2-baae-11f56a27116e"
      },
      "cell_type": "markdown",
      "source": "FastText"
    },
    {
      "metadata": {
        "scrolled": true,
        "_uuid": "caf5fe6d19422f715fb9ebb63f5d0e123cb3650d",
        "_cell_guid": "8d94ab52-7adb-4b6b-b8ed-2db2aaac7321",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "model = cnn_model(embedding_matrix_fast)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "2c4fd42aa66318d4168561fcccdbdbf8735e9ac2",
        "_cell_guid": "7472bd4b-a8b9-4401-8c4c-6fc777988f9d",
        "trusted": false
      },
      "cell_type": "code",
      "source": "hist = model.fit(X_t, y, \n                 epochs=num_epochs, \n                 callbacks=callbacks_list, \n                 validation_split=0.2, shuffle=True, batch_size=batch_size)\nmodel.save_weights(\"cnn_model_fast.h5\")\nprint(\"Saved model to disk\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "26be9dd82af03a07557b32425108bd055f3933b6",
        "_cell_guid": "571c91f1-3eeb-487a-ba5e-28c070297838",
        "trusted": false
      },
      "cell_type": "code",
      "source": "y_test = model.predict(X_te, batch_size=32, verbose=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "78fa4fbe86a7b7316b39c5b61f5357c3f755ac4c",
        "_cell_guid": "d448f87e-4b66-42c8-9338-75bea0399416",
        "trusted": false
      },
      "cell_type": "code",
      "source": "submission_df = pd.DataFrame(columns=['id'] + list_classes)\nsubmission_df['id'] = test['id'].values \nsubmission_df[list_classes] = y_test \nsubmission_df.to_csv(\"./cnn_submission_fast.csv\", index=False)",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}